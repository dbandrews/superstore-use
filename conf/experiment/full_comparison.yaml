# @package _global_

# Full comparison experiment - compare multiple LLMs
# Run with: uv run -m src.eval.cli +experiment=full_comparison

defaults:
  - override /browser: headless
  - override /prompt: default

name: full_comparison
items:
  # Easy
  - 2% milk
  - 6 bananas
  # Medium
  - Kraft mac and cheese
  - Heinz ketchup
  # Hard
  - 4 Honeycrisp apples

max_steps: 30
timeout_seconds: 300.0
clear_cart_before_run: true

# Note: To compare LLMs, use multirun:
# uv run -m src.eval.cli --multirun llm=gpt4,llama_70b,gpt_oss_120b +experiment=full_comparison
